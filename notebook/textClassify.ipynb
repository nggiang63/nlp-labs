{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa9e6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- sentiment: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark \n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"NLP-classification\").getOrCreate()\n",
    "val path = \"/home/giangnt/Downloads/NLP_DL/nlp-labs/data/sentiments.csv\"\n",
    "df = spark.read.csv(path, header=True)\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e00995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|                text|sentiment|\n",
      "+--------------------+---------+\n",
      "|Kickers on my wat...|        1|\n",
      "|user: AAP MOVIE. ...|        1|\n",
      "|user I'd be afrai...|        1|\n",
      "|     MNTA Over 12.00|        1|\n",
      "|      OI  Over 21.37|        1|\n",
      "+--------------------+---------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfacce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|sentiment|count|\n",
      "+---------+-----+\n",
      "|       -1| 2106|\n",
      "|     NULL|    1|\n",
      "|        1| 3685|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"sentiment\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0bbebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|sentiment|count|\n",
      "+---------+-----+\n",
      "|       -1| 2106|\n",
      "|        1| 3685|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.groupBy(\"sentiment\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81af55ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF, StringIndexer, RegexTokenizer\n",
    "\n",
    "# set string indexer\n",
    "string_indexer = StringIndexer(inputCol=\"sentiment\", outputCol=\"label\")\n",
    "# df = string_indexer.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9729d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- sentiment: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5c000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize\n",
    "tokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\", pattern=\"[\\s,.;:!?`'\\\"(){\\}_-]+\")\n",
    "# df = tokenizer.transform(df)\n",
    "# df.select(\"text\", \"words\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3257b3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(inputCol=\"words\", outputCol=\"vector\")\n",
    "# df = vectorizer.fit(df).transform(df)\n",
    "# df.select(\"words\", \"vector\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e315a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "classifier = LogisticRegression(featuresCol=\"vector\", labelCol=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b27ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[string_indexer, tokenizer, vectorizer, classifier])\n",
    "model = pipeline.fit(df)\n",
    "output = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eee6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|                text|sentiment|label|               words|              vector|       rawPrediction|         probability|prediction|\n",
      "+--------------------+---------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|Kickers on my wat...|        1|  0.0|[kickers, on, my,...|(10580,[3,41,44,4...|[20.4240630582554...|[0.99999999865121...|       0.0|\n",
      "|user: AAP MOVIE. ...|        1|  0.0|[user, aap, movie...|(10580,[0,6,7,12,...|[27.9766446916048...|[0.99999999999929...|       0.0|\n",
      "|user I'd be afrai...|        1|  0.0|[user, i, d, be, ...|(10580,[1,2,4,8,1...|[21.4963954038287...|[0.99999999953843...|       0.0|\n",
      "|     MNTA Over 12.00|        1|  0.0|[mnta, over, 12, 00]|(10580,[22,121,14...|[37.5158690792516...|           [1.0,0.0]|       0.0|\n",
      "|      OI  Over 21.37|        1|  0.0|  [oi, over, 21, 37]|(10580,[22,307,42...|[28.3070030382000...|[0.99999999999949...|       0.0|\n",
      "+--------------------+---------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "output.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38021cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(text='Kickers on my watchlist XIDE TIT SOQ PNK CPW BPZ AJ  trade method 1 or method 2, see prev posts', sentiment='1', label=0.0, words=['kickers', 'on', 'my', 'watchlist', 'xide', 'tit', 'soq', 'pnk', 'cpw', 'bpz', 'aj', 'trade', 'method', '1', 'or', 'method', '2', 'see', 'prev', 'posts'], vector=SparseVector(10580, {3: 1.0, 41: 1.0, 44: 1.0, 46: 1.0, 77: 1.0, 85: 1.0, 86: 1.0, 445: 1.0, 1536: 1.0, 2527: 1.0, 3158: 1.0, 3740: 1.0, 3999: 1.0, 4574: 2.0, 4787: 1.0, 4900: 1.0, 5652: 1.0, 7445: 1.0, 8432: 1.0}), rawPrediction=DenseVector([20.4241, -20.4241]), probability=DenseVector([1.0, 0.0]), prediction=0.0)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1de2bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|label|prediction|\n",
      "+-----+----------+\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "+-----+----------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "output.select(\"label\", \"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc97d6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.evaluation \n",
    "evaluator = pyspark.ml.evaluation.BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"prediction\")\n",
    "# accuracy = evaluator.evaluate(output)\n",
    "# print(\"Accuracy =\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c952b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train count: 4607\n",
      "Test count: 1184\n"
     ]
    }
   ],
   "source": [
    "# split\n",
    "train, test = df.randomSplit([0.8, 0.2], seed=1)\n",
    "print(\"Train count:\", train.count())\n",
    "print(\"Test count:\", test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa828b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(train)\n",
    "test_output = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19933bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7323536924348284"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2ffdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Word2Vec\n",
    "w2vec = Word2Vec(inputCol=\"words\", outputCol=\"vector_w2v\", vectorSize=100)\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"zeroshot/twitter-financial-news-sentiment\")\n",
    "new_pipeline = Pipeline(stages=[string_indexer, tokenizer, w2vec, classifier])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d64e6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = new_pipeline.fit(train)\n",
    "new_test_output = new_model.transform(test)\n",
    "evaluator.evaluate(new_test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21352825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e852423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"zeroshot/twitter-financial-news-sentiment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
